{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "# from scipy.linalg import svd\n",
    "\n",
    "import scipy.sparse\n",
    "from sparsesvd import sparsesvd\n",
    "from scipy.linalg import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>following</th>\n",
       "      <th>rating</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>josh</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nishowsan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benschwarz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nishowsan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrew</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nishowsan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tmm1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nishowsan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mitsuhiko</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nishowsan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    following  rating   username\n",
       "0        josh     1.0  nishowsan\n",
       "1  benschwarz     1.0  nishowsan\n",
       "2      andrew     1.0  nishowsan\n",
       "3        tmm1     1.0  nishowsan\n",
       "4   mitsuhiko     1.0  nishowsan"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assumes transferred files from local to this aws machine via:\n",
    "# scp -i ~/.ssh/aws_key_sumac.pem data/* ubuntu@54.67.117.7:github_rec/\n",
    "\n",
    "with open(\"df.pickle\", \"rb\") as input_file:\n",
    "    df = pickle.load(input_file)\n",
    "    \n",
    "#df.head()\n",
    "\n",
    "with open(\"df4.pickle\", \"rb\") as input_file: \n",
    "    dfstacked = pickle.load(input_file)\n",
    "    \n",
    "# dfstacked.head()\n",
    "\n",
    "with open(\"stacked_zeros_df.pickle\", \"rb\") as input_file: \n",
    "    stacked_zeros_df = pickle.load(input_file)\n",
    "    \n",
    "stacked_zeros_df.head()\n",
    "# /Users/sumac/projects/metis/github_recommender/data/df.pickle - 3 col\n",
    "# /Users/sumac/projects/metis/github_recommender/data/df4.pickle - stacked format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_zeros_df.rename(columns={'rating':'all_ratings'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_zeros_df = stacked_zeros_df[['username', 'following', 'all_ratings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using surprise to get recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "stacked_zeros_df.head()\n",
    "\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "#data = Dataset.load_from_df(stacked_zeros_df[['username', 'following', 'rating']], reader)\n",
    "data2 = Dataset.load_from_df(stacked_zeros_df[['username', 'following', 'all_ratings']], reader)\n",
    "\n",
    "# We can now use this dataset as we please, e.g. calling cross_validate\n",
    "model1 = cross_validate(NormalPredictor(), data2, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np = NormalPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.fit(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # can we extract the predictions?\n",
    "# # code from surprise website\n",
    "\n",
    "# uid = str(196)  # raw user id (as in the ratings df). They are **strings**!\n",
    "# iid = str(302)  # raw item id (as in the ratings df). They are **strings**!\n",
    "\n",
    "# # get a prediction for specific users and items\n",
    "# pred = algo.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x116e48be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "\n",
    "\n",
    "# Retrieve the trainset.\n",
    "trainset = data2.build_full_trainset()\n",
    "\n",
    "# Build an algorithm and train it\n",
    "algo = KNNBasic()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: nishowsan  item: andrew     r_ui = 4.00   est = 1.00   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# # test known True following pair\n",
    "# uid = 'nishowsan'  # raw user id - string\n",
    "# iid = 'andrew'  # raw item id - string\n",
    "\n",
    "# # get a prediction for specific user and items\n",
    "# pred = algo.predict(uid, iid, r_ui=4, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred.est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>rating</th>\n",
       "      <th>following</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>donnemartin</td>\n",
       "      <td>1</td>\n",
       "      <td>mitsuhiko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>donnemartin</td>\n",
       "      <td>1</td>\n",
       "      <td>kenneth-reitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>donnemartin</td>\n",
       "      <td>1</td>\n",
       "      <td>wesm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>donnemartin</td>\n",
       "      <td>1</td>\n",
       "      <td>jakevdp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mitsuhiko</td>\n",
       "      <td>1</td>\n",
       "      <td>brosner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      username  rating      following\n",
       "0  donnemartin       1      mitsuhiko\n",
       "1  donnemartin       1  kenneth-reitz\n",
       "2  donnemartin       1           wesm\n",
       "3  donnemartin       1        jakevdp\n",
       "4    mitsuhiko       1        brosner"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"df4.pickle\", \"rb\") as input_file: \n",
    "    df_stacked = pickle.load(input_file)\n",
    "    \n",
    "df_stacked.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>following</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30133</th>\n",
       "      <td>johbo</td>\n",
       "      <td>netme qknight PythonicNinja ticosax globin vcu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19656</th>\n",
       "      <td>python-bugzilla</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22661</th>\n",
       "      <td>alex2</td>\n",
       "      <td>mtarbit ask toastdriven caolan dtt101 Jc2k jac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9528</th>\n",
       "      <td>orhanobut</td>\n",
       "      <td>JakeWharton yekmer tasomaniac keklikhasan oguz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>neil-tan</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28129</th>\n",
       "      <td>kapsiry</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>aziz</td>\n",
       "      <td>defunkt technoweenie drnic peterc ryanb rtomay...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              username                                          following  \\\n",
       "30133            johbo  netme qknight PythonicNinja ticosax globin vcu...   \n",
       "19656  python-bugzilla                                                      \n",
       "22661            alex2  mtarbit ask toastdriven caolan dtt101 Jc2k jac...   \n",
       "9528         orhanobut  JakeWharton yekmer tasomaniac keklikhasan oguz...   \n",
       "3542          neil-tan                                                      \n",
       "28129          kapsiry                                                      \n",
       "334               aziz  defunkt technoweenie drnic peterc ryanb rtomay...   \n",
       "\n",
       "       rating  \n",
       "30133       1  \n",
       "19656       1  \n",
       "22661       1  \n",
       "9528        1  \n",
       "3542        1  \n",
       "28129       1  \n",
       "334         1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_following(username):\n",
    "\n",
    "    following = set(df.loc[df['username'] == username, 'following'])  # get list username _is_ following\n",
    "    \n",
    "    all_follows = set(df_stacked['username'].unique() + dfstacked['following']) # get list everyone has followed, all poss.\n",
    "\n",
    "    not_following = list(all_follows - following) # difference is list of people username is not following    \n",
    "        \n",
    "    return not_following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = {} # collect to export for flask app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to loop over each user in original df, run prediction on each user\n",
    "\n",
    "target_user = 'vassim'\n",
    "\n",
    "# need func to get list of users in \"following\" column, minus those entries for \n",
    "\n",
    "not_following_list = get_not_following(target_user) # [ALL THE USERS target_user IS NOT FOLLOWING] \n",
    "\n",
    "estimated_scores = []\n",
    "\n",
    "for user in not_following_list:\n",
    "\n",
    "    current_score = algo.predict(target_user, user).est\n",
    "\n",
    "    estimated_scores.append((current_score, user))\n",
    "\n",
    "#print(estimated_scores)\n",
    "sorted_scores = sorted(estimated_scores, reverse = True, key = lambda x: x[0])\n",
    "\n",
    "recs[target_user] = sorted_scores[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export predictions table for use in flask app for quick demo solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "json = json.dumps(recs)\n",
    "f = open(\"recs.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to pull down this file and recs.json to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unused code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create sparse/dense matrices for use with non-surprise libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>following</th>\n",
       "      <th>rating</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>josh</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nishowsan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benschwarz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nishowsan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrew</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nishowsan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tmm1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nishowsan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mitsuhiko</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nishowsan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    following  rating   username\n",
       "0        josh     1.0  nishowsan\n",
       "1  benschwarz     1.0  nishowsan\n",
       "2      andrew     1.0  nishowsan\n",
       "3        tmm1     1.0  nishowsan\n",
       "4   mitsuhiko     1.0  nishowsan"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_zeros_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('rating', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = cv.fit_transform(df.following) # creates dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = cv1.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (6966, 0)\t1\n",
      "  (6920, 1)\t1\n",
      "  (8709, 2)\t1\n",
      "  (45105, 3)\t1\n",
      "  (23822, 4)\t1\n",
      "  (6603, 5)\t1\n",
      "  (9021, 5)\t1\n",
      "  (5416, 6)\t1\n",
      "  (1948, 7)\t1\n",
      "  (6901, 7)\t1\n",
      "  (13810, 7)\t1\n",
      "  (37018, 7)\t1\n",
      "  (48907, 7)\t1\n",
      "  (45386, 8)\t1\n",
      "  (46137, 9)\t1\n",
      "  (48401, 10)\t1\n",
      "  (2163, 11)\t1\n",
      "  (68, 12)\t1\n",
      "  (17032, 13)\t1\n",
      "  (40101, 14)\t1\n",
      "  (32251, 15)\t1\n",
      "  (26274, 16)\t1\n",
      "  (35478, 17)\t1\n",
      "  (10450, 18)\t1\n",
      "  (31307, 18)\t1\n",
      "  :\t:\n",
      "  (45025, 175775)\t1\n",
      "  (45645, 175775)\t1\n",
      "  (45743, 175775)\t1\n",
      "  (47977, 175775)\t1\n",
      "  (5794, 175776)\t1\n",
      "  (37297, 175777)\t1\n",
      "  (25464, 175778)\t1\n",
      "  (44837, 175779)\t1\n",
      "  (23125, 175780)\t1\n",
      "  (38759, 175781)\t1\n",
      "  (42594, 175782)\t1\n",
      "  (29728, 175783)\t1\n",
      "  (42899, 175784)\t1\n",
      "  (5208, 175785)\t1\n",
      "  (31713, 175785)\t1\n",
      "  (10944, 175786)\t1\n",
      "  (21980, 175787)\t1\n",
      "  (39307, 175787)\t1\n",
      "  (18348, 175788)\t1\n",
      "  (32787, 175788)\t1\n",
      "  (44587, 175788)\t1\n",
      "  (16434, 175789)\t1\n",
      "  (20052, 175790)\t1\n",
      "  (42461, 175790)\t1\n",
      "  (45882, 175791)\t1\n"
     ]
    }
   ],
   "source": [
    "print(cv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try with sparsesvd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U, Sigma, VT = svd(cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut, s, vt = sparsesvd(cv2, 100) # https://pypi.org/project/sparsesvd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 175792)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109919]\n"
     ]
    }
   ],
   "source": [
    "def get_recommends(itemID, vt, num_recom=4):\n",
    "    recs = []\n",
    "    for item in range(vt.T.shape[0]):\n",
    "        if item != itemID:\n",
    "            recs.append([item,np.dot(vt.T[itemID],vt.T[item])])\n",
    "    #print(recs[:4])\n",
    "    #print(len(recs))\n",
    "    final_rec = [i[0] for i in sorted(recs,key=lambda x: x[1],reverse=True)]\n",
    "    return final_rec[:num_recom]\n",
    "\n",
    "print(get_recommends(0,vt,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.13581707e-06, -2.62145678e-06, -6.60407669e-07, -5.73848740e-08,\n",
       "        5.15191641e-06,  7.55844065e-06, -3.10182000e-06, -1.52120974e-05,\n",
       "        1.81528372e-05,  1.82933947e-05, -3.97383912e-06,  9.94486488e-07,\n",
       "       -7.03583927e-06,  8.03047356e-06,  2.28077663e-05,  5.70432093e-06,\n",
       "       -1.16204214e-05, -2.50122717e-05,  1.67223970e-05,  1.57086305e-05,\n",
       "       -2.61964427e-05, -1.29284410e-05, -1.02520769e-05, -1.31802649e-05,\n",
       "        8.70263187e-06,  1.54513950e-05, -5.72642714e-05, -2.68605490e-05,\n",
       "       -1.30359171e-05, -1.79817007e-05,  2.12396259e-05,  5.68859637e-06,\n",
       "        2.37622986e-05, -1.57213702e-05, -5.11272912e-05, -3.21831649e-05,\n",
       "        4.29779352e-05,  5.06508499e-05, -2.11629070e-05,  4.77075291e-05,\n",
       "        6.26479932e-05, -2.36916005e-05, -1.53229047e-05,  6.29408853e-05,\n",
       "       -3.53995648e-05,  1.58488552e-05,  4.54988493e-05, -1.31862795e-05,\n",
       "       -1.93202359e-05, -2.21882812e-05, -8.10110230e-06,  4.26991634e-05,\n",
       "       -2.74455158e-05, -4.39135240e-05, -4.33453357e-05,  1.66051131e-05,\n",
       "        2.53924906e-05, -5.18694284e-05, -5.77686751e-05,  1.07448246e-05,\n",
       "       -4.06170484e-05, -4.79271394e-05, -3.46023820e-05, -4.64174442e-05,\n",
       "       -4.14128278e-05, -1.35945197e-05,  7.48596752e-07,  4.86925354e-05,\n",
       "        4.32411150e-07,  2.64781793e-05, -5.94221665e-05, -4.06136961e-05,\n",
       "       -2.49723562e-05, -7.11378604e-05, -2.09478221e-05,  9.92484043e-05,\n",
       "        8.49154080e-05,  5.83318711e-05,  1.41865611e-06, -3.64597487e-05,\n",
       "        1.37272616e-05, -7.52075912e-05,  2.22533260e-05,  1.33228996e-04,\n",
       "        3.85518055e-05,  4.21826198e-05,  1.56738855e-04, -1.44889796e-04,\n",
       "        1.07932747e-04,  1.16600784e-05,  8.11884636e-05, -3.67361950e-05,\n",
       "       -2.55532436e-05, -1.62374834e-05,  3.87322873e-05, -1.38618647e-05,\n",
       "       -5.61567335e-05,  5.87809542e-05,  8.44725740e-05,  4.88483483e-05])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49189, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommends_user(userID, U, df):\n",
    "    userrecs = []\n",
    "    for user in range(U.shape[0]):\n",
    "        if user!= userID:\n",
    "            userrecs.append([user,np.dot(U[userID],U[user])])\n",
    "    final_rec = [i[0] for i in sorted(userrecs,key=lambda x: x[1],reverse=True)]\n",
    "    comp_user = final_rec[0]\n",
    "    print(\"User #%s's most similar user is User #%s \"% (userID, comp_user))\n",
    "    rec_likes = df.iloc[comp_user]\n",
    "    current = df.iloc[userID]\n",
    "    recs = []\n",
    "    for i,item in enumerate(current):\n",
    "        if item != rec_likes[i] and rec_likes[i]!=0:\n",
    "            recs.append(i)\n",
    "    return recs\n",
    "\n",
    "user_to_rec = 0\n",
    "\n",
    "print(\"Items for User %s to check out: \"% user_to_rec, get_recommends_user(user_to_rec,ut,df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc([[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try with knn surprise method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://surprise.readthedocs.io/en/stable/FAQ.html#how-to-get-the-k-nearest-neighbors-of-a-user-or-item\n",
    "\n",
    "#import io  # needed because of weird encoding of u.item file\n",
    "from surprise import KNNBaseline\n",
    "from surprise import Dataset\n",
    "#from surprise import get_dataset_dir\n",
    "\n",
    "\n",
    "def read_item_names():\n",
    "    \"\"\"Read the u.item file from MovieLens 100-k dataset and return two\n",
    "    mappings to convert raw ids into movie names and movie names into raw ids.\n",
    "    \"\"\"\n",
    "\n",
    "#     file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "#     rid_to_name = {}\n",
    "#     name_to_rid = {}\n",
    "\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = line[1]\n",
    "            name_to_rid[line[1]] = line[0]\n",
    "\n",
    "    return rid_to_name, name_to_rid\n",
    "\n",
    "###\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(dfs[['username', 'following', 'rating']], reader)\n",
    "\n",
    "# We can now use this dataset as we please, e.g. calling cross_validate\n",
    "cross_validate(NormalPredictor(), data, cv=2)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "# First, train the algortihm to compute the similarities between items\n",
    "# data = Dataset.load_builtin('ml-100k')\n",
    "# trainset = data.build_full_trainset()\n",
    "\n",
    "\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "algo = KNNBaseline(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Read the mappings raw id <-> movie name\n",
    "rid_to_name, name_to_rid = read_item_names()\n",
    "\n",
    "# Retrieve inner id of the movie Toy Story\n",
    "toy_story_raw_id = name_to_rid['Toy Story (1995)']\n",
    "toy_story_inner_id = algo.trainset.to_inner_iid(toy_story_raw_id)\n",
    "\n",
    "# Retrieve inner ids of the nearest neighbors of Toy Story.\n",
    "toy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=10)\n",
    "\n",
    "# Convert inner ids of the neighbors into names.\n",
    "toy_story_neighbors = (algo.trainset.to_raw_iid(inner_id)\n",
    "                       for inner_id in toy_story_neighbors)\n",
    "toy_story_neighbors = (rid_to_name[rid]\n",
    "                       for rid in toy_story_neighbors)\n",
    "\n",
    "print()\n",
    "print('The 10 nearest neighbors of Toy Story are:')\n",
    "for movie in toy_story_neighbors:\n",
    "    print(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict rating eventually\n",
    "\n",
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(302)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
